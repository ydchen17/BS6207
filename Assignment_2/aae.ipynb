{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AAE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2"
      ],
      "metadata": {
        "id": "Q4p2OYgWVhjf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## (b) Design another neural network “dis_net” to discriminate between blur images and clear images. \n",
        "\n",
        "- Blur images can be generated by taking the original MNIST data and do some gaussian blur. \n",
        "- Train autoencoder with L1-norm reconstruction loss + discriminator loss.\n",
        "- Make reconstructed images as clear as possible, that is, the auto encoder will need to be trained so that “dis_net” score it as a clear image \n",
        "- Compare results between (a) and (b)"
      ],
      "metadata": {
        "id": "HV4w6Gm9rxwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "Opc6-oqWMQB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST Dataset \n",
        "dataset = dsets.MNIST(root='./data', \n",
        "                      train=True, \n",
        "                      transform=transforms.ToTensor(),  \n",
        "                      download=True)\n",
        "\n",
        "# Data Loader (Input PipeLineareare)\n",
        "data_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
        "                                          batch_size=100, \n",
        "                                          shuffle=True)\n",
        "\n",
        "def to_np(x):\n",
        "    return x.data.cpu().numpy()\n",
        "\n",
        "def to_var(x):\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cuda()\n",
        "    return Variable(x) "
      ],
      "metadata": {
        "id": "aByDUgeCMlPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoder\n",
        "class Encoder(nn.Module):  \n",
        "    def __init__(self,X_dim,N,z_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.Linear1 = nn.Linear(X_dim, N)\n",
        "        self.Linear2 = nn.Linear(N, N)\n",
        "        self.Linear3gauss = nn.Linear(N, z_dim)\n",
        "    def forward(self, x):\n",
        "        x = F.dropout(self.Linear1(x), p=0.25, training=self.training)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(self.Linear2(x), p=0.25, training=self.training)\n",
        "        x = F.relu(x)\n",
        "        xgauss = self.Linear3gauss(x)\n",
        "        return xgauss"
      ],
      "metadata": {
        "id": "iDeR_bafMn2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder\n",
        "class Decoder(nn.Module):  \n",
        "    def __init__(self,X_dim,N,z_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.Linear1 = nn.Linear(z_dim, N)\n",
        "        self.Linear2 = nn.Linear(N, N)\n",
        "        self.Linear3 = nn.Linear(N, X_dim)\n",
        "    def forward(self, x):\n",
        "        x = F.dropout(self.Linear1(x), p=0.25, training=self.training)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(self.Linear2(x), p=0.25, training=self.training)\n",
        "        x = self.Linear3(x)\n",
        "        return torch.sigmoid(x)"
      ],
      "metadata": {
        "id": "kPbuA5KxMosF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminator\n",
        "class Dis_Net(nn.Module):  \n",
        "    def __init__(self,N,z_dim):\n",
        "        super(Dis_Net, self).__init__()\n",
        "        self.Linear1 = nn.Linear(z_dim, N)\n",
        "        self.Linear2 = nn.Linear(N, N)\n",
        "        self.Linear3 = nn.Linear(N, 1)\n",
        "    def forward(self, x):\n",
        "        x = F.dropout(self.Linear1(x), p=0.2, training=self.training)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(self.Linear2(x), p=0.2, training=self.training)\n",
        "        x = F.relu(x)\n",
        "        return torch.sigmoid(self.Linear3(x))"
      ],
      "metadata": {
        "id": "oWHItjU7Mqx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPS = 1e-15\n",
        "z_red_dims = 16\n",
        "Q = Encoder(784,1000,z_red_dims).cuda()\n",
        "P = Decoder(784,1000,z_red_dims).cuda()\n",
        "D_gauss = Dis_Net(500,z_red_dims).cuda()"
      ],
      "metadata": {
        "id": "OvKwyLrEMs6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set learning rates\n",
        "gen_lr = 0.0001\n",
        "reg_lr = 0.00005\n",
        "\n",
        "#encode/decode optimizers\n",
        "optim_P = torch.optim.Adam(P.parameters(), lr=gen_lr)\n",
        "optim_Q_enc = torch.optim.Adam(Q.parameters(), lr=gen_lr)\n",
        "#regularizing optimizers\n",
        "optim_Q_gen = torch.optim.Adam(Q.parameters(), lr=reg_lr)\n",
        "optim_D = torch.optim.Adam(D_gauss.parameters(), lr=reg_lr)\n",
        "    \n",
        "data_iter = iter(data_loader)\n",
        "iter_per_epoch = len(data_loader)\n",
        "total_step = 50000"
      ],
      "metadata": {
        "id": "aXxsXHGPNvin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training\n",
        "for step in range(total_step):\n",
        "\n",
        "    # Reset the data_iter\n",
        "    if (step+1) % iter_per_epoch == 0:\n",
        "        data_iter = iter(data_loader)\n",
        "\n",
        "    # Fetch the images and labels and convert them to variables\n",
        "    images, labels = next(data_iter)\n",
        "    images, labels = to_var(images.view(images.size(0), -1)), to_var(labels)\n",
        "\n",
        "    #reconstruction loss\n",
        "    P.zero_grad()\n",
        "    Q.zero_grad()\n",
        "    D_gauss.zero_grad()\n",
        "\n",
        "    z_sample = Q(images)   #encode to z\n",
        "    X_sample = P(z_sample) #decode to X reconstruction\n",
        "    recon_loss = F.l1_loss(X_sample+EPS,images+EPS)\n",
        "\n",
        "    recon_loss.backward()\n",
        "    optim_P.step()\n",
        "    optim_Q_enc.step()\n",
        "\n",
        "    # Discriminator\n",
        "    ## true prior is random normal (randn)\n",
        "    ## this is constraining the Z-projection to be normal!\n",
        "    Q.eval()\n",
        "    z_real_gauss = Variable(torch.randn(images.size()[0], z_red_dims) * 5.).cuda()\n",
        "    D_real_gauss = D_gauss(z_real_gauss)\n",
        "\n",
        "    z_fake_gauss = Q(images)\n",
        "    D_fake_gauss = D_gauss(z_fake_gauss)\n",
        "\n",
        "    D_loss = -torch.mean(torch.log(D_real_gauss + EPS) + torch.log(1 - D_fake_gauss + EPS))\n",
        "\n",
        "    D_loss.backward()\n",
        "    optim_D.step()\n",
        "\n",
        "    # Generator\n",
        "    Q.train()\n",
        "    z_fake_gauss = Q(images)\n",
        "    D_fake_gauss = D_gauss(z_fake_gauss)\n",
        "    G_loss = -torch.mean(torch.log(D_fake_gauss + EPS))\n",
        "    G_loss.backward()\n",
        "    optim_Q_gen.step()   \n",
        "\n",
        "#save the Encoder\n",
        "torch.save(Q.state_dict(),'Q_encoder_weights.pt')"
      ],
      "metadata": {
        "id": "UkioqqjChWm-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}